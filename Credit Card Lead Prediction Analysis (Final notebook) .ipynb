{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "import time\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "import pandas_profiling\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.core.dtypes.common import (is_numeric_dtype, is_datetime64_dtype, is_bool_dtype)\n",
    "import optuna   \n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filename):\n",
    "    dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    name,ext = os.path.splitext(filename)\n",
    "    if ext == '.csv':\n",
    "        data = pd.read_csv(filename,low_memory=False,parse_dates= True,infer_datetime_format = True,date_parser = dateparse)\n",
    "    if ext == '.json':\n",
    "        data = pd.read_json(filename)\n",
    "    if ext =='.xlsx' or ext == '.xls':\n",
    "        data == pd.read_excel(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = import_data('/home/divyanka/Downloads/train_s3TEQDk.csv')\n",
    "test = import_data('/home/divyanka/Downloads/test_mSzZ8RL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :param string: str, string to check for date\n",
    "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def d_type(df):\n",
    "    for col in df[:1]:\n",
    "        val = df[:1][col]\n",
    "        if val.dtypes == object:\n",
    "            try:\n",
    "                if is_date(val.astype(str).values[0]):\n",
    "                    df[col] = pd.to_datetime(df[col])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return df\n",
    "train = d_type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing And Zero Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_zero_values_table(data):\n",
    "    zero_val = (data == 0).sum(axis=0)\n",
    "    #zero_val = (df == \"0\").astype(int).sum(axis=0)\n",
    "    mis_val = data.isnull().sum()\n",
    "    mis_val_percent = 100 * data.isnull().sum() / len(data)\n",
    "    mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n",
    "    mz_table = mz_table.rename(\n",
    "    columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n",
    "    mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n",
    "    mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(data)\n",
    "    mz_table['Data Type'] = data.dtypes\n",
    "    mz_table = mz_table[\n",
    "    mz_table.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(data.shape[1]) + \" columns and \" + str(data.shape[0]) + \" Rows.\\n\" \n",
    "    \"There are \" + str(mz_table.shape[0]) +\n",
    "    \" columns that have missing values. \\n\")\n",
    "    # mz_table.to_excel('D:/sampledata/missing_and_zero_values.xlsx', freeze_panes=(1,0), index = False)\n",
    "    return mz_table\n",
    "\n",
    "missing = missing_zero_values_table(train)\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Duplicate, Normal, Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_non_unique_and_dup(df, n=2):\n",
    "    \"\"\" Remove all the columns having less than 2 unique values and duplicate records\"\"\"\n",
    "    try:\n",
    "        print(\"Number of duplicate records : \",len(df) - len(df.drop_duplicates()))\n",
    "        #df.drop_duplicates(inplace=True)\n",
    "        col_list = []\n",
    "        cnt = 0\n",
    "        for col in df.columns:\n",
    "            if df[col].nunique() <= n:\n",
    "                #df.drop(col,inplace=True)\n",
    "                col_list.append(col)\n",
    "                #cnt = cnt + 1\n",
    "        print(\"Number of non unique and duplicate columns : \",len(col_list))\n",
    "        print(\"Column Names:\")\n",
    "        print(col_list)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def check_norm(df,alpha=0.5):\n",
    "    \"\"\"Returns 1 if the data is normal  otherwise 0,saves the plots of the distribution in /plots directory\"\"\"\n",
    "    try:\n",
    "        col_list=[]\n",
    "        for column in df.columns:\n",
    "            if is_numeric_dtype(df[column]):\n",
    "                #plt.hist(df[column], color='blue', edgecolor='black')\n",
    "        #plt.savefig(directory + col_name + \"_normplot\"+time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        #plt.close()\n",
    "                #stats.probplot(df[column], plot=plt)\n",
    "        #plt.savefig(directory + col_name + \"_probplot\"+time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        #plt.close()\n",
    "                stat, p = normaltest(df[column])\n",
    "                if  not p > alpha:\n",
    "                    col_list.append(column)\n",
    "        return col_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def check_balanced(df):\n",
    "    \"\"\"Returns the list of column features which are unbalanced\"\"\"\n",
    "    try:\n",
    "        unbalanced = []\n",
    "        for column in df.columns:    \n",
    "            l = len(df[column])\n",
    "            nun = 100/df[column].nunique()\n",
    "            val_high , val_low = nun+(nun*0.2),nun-(nun*0.2)\n",
    "            for cat in df[column].unique():\n",
    "                chk_percent = (len(df[df[column]==cat])/l)*100\n",
    "                if chk_percent > val_high or chk_percent < val_low:\n",
    "                    unbalanced.append(column)\n",
    "        return list(set(unbalanced))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of non unique and duplicate columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_non_unique_and_dup(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of columns not having normal data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_norm(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of columns having unbalanced feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_balanced(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = train.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_by_num_type(dataframe):\n",
    "    print('***********Skewness************\\n')\n",
    "    print(data_num.skew())\n",
    "    print('\\n***********Kurtosis************\\n')\n",
    "    print(data_num.kurtosis())\n",
    "    print('\\n***********Sum*************\\n')\n",
    "    print(data_num.sum())\n",
    "    print('\\n***********Median**********\\n')\n",
    "    print(data_num.median())\n",
    "    print('\\n***********Variance********\\n')\n",
    "    print(data_num.var())\n",
    "    print('\\n***********Mean Absolute Deviation***********\\n')\n",
    "    print(data_num.mad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe_by_num_type(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n**********Correlation**********\\n')\n",
    "data_num.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n************Co-Variance*************\\n')\n",
    "data_num.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bool/Object Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = train.select_dtypes(include=[np.object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_datetime = train.select_dtypes(include=[np.datetime64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_datetime.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Counts for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_counts(dataframe):\n",
    "    \"\"\"\n",
    "    prints value counts for each (categorical) column\n",
    "    :param dataframe: a pandas DataFrame\n",
    "    :param max_nunique: the max number of unique values a column can have for\n",
    "                        its value counts to be printed; no limit is set if None\n",
    "    :param numeric: boolean; if True, value counts for numeric data are also\n",
    "                    printed\n",
    "    :param datetime: boolean; if True, value counts for datetime data are also\n",
    "                     printed\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for column in dataframe.columns:\n",
    "        col = dataframe[column]\n",
    "        \n",
    "        #if is_bool_dtype(col):\n",
    "         #   print(col.value_counts().nlargest(5))\n",
    "          #  print('\\n')\n",
    "        if is_numeric_dtype(col):\n",
    "            print(col.value_counts().nlargest(10))\n",
    "            print('\\n')\n",
    "        elif is_datetime64_dtype(col):\n",
    "            print(col.value_counts().nlargest(10))\n",
    "            print('\\n')\n",
    "        else:\n",
    "            print(col.value_counts().nlargest(10))\n",
    "            print('\\n')\n",
    "            \n",
    "        '''if not any([\n",
    "            max_nunique is not None and col.nunique() > max_nunique,\n",
    "            not numeric and is_numeric_dtype(col),\n",
    "            not datetime and is_datetime64_dtype(col)\n",
    "        ]):\n",
    "            print(col.value_counts())\n",
    "            print('\\n')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_counts(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pfr = pandas_profiling.ProfileReport(train)\n",
    "pfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "report = sv.analyze(train)\n",
    "report.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "AV = AutoViz_Class()\n",
    "data = AV.AutoViz('/home/divyanka/Downloads/train_s3TEQDk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "tr1=go.Box(x=train['Age'],name='Age Box Plot',boxmean=True)\n",
    "tr2=go.Histogram(x=train['Age'],name='Age Histogram')\n",
    "\n",
    "fig.add_trace(tr1,row=1,col=1)\n",
    "fig.add_trace(tr2,row=2,col=1)\n",
    "\n",
    "fig.update_layout(height=700, width=1200, title_text=\"Distribution of Customer Ages\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "tr1=go.Box(x=train['Avg_Account_Balance'],name='Avg Account Balance Box Plot',boxmean=True)\n",
    "tr2=go.Histogram(x=train['Avg_Account_Balance'],name='Avg Account Balance Histogram')\n",
    "\n",
    "fig.add_trace(tr1,row=1,col=1)\n",
    "fig.add_trace(tr2,row=2,col=1)\n",
    "\n",
    "fig.update_layout(height=700, width=1200, title_text=\"Distribution of Customer Avg Account Balance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "tr1=go.Box(x=train['Vintage'],name='Vintage Box Plot',boxmean=True)\n",
    "tr2=go.Histogram(x=train['Vintage'],name='Vintage Histogram')\n",
    "\n",
    "fig.add_trace(tr1,row=1,col=1)\n",
    "fig.add_trace(tr2,row=2,col=1)\n",
    "\n",
    "fig.update_layout(height=700, width=1200, title_text=\"Distribution of Customer Vintage\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train, col = \"Is_Lead\")\n",
    "g.map(sns.distplot, \"Age\", bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, cols=2,subplot_titles=('','<b>Is Active','<b>Not Active<b>','Residuals'),\n",
    "    vertical_spacing=0.09,\n",
    "    specs=[[{\"type\": \"pie\",\"rowspan\": 2}       ,{\"type\": \"pie\"}] ,\n",
    "           [None                               ,{\"type\": \"pie\"}]            ,                                      \n",
    "          ]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(values=train.Gender.value_counts().values,labels=['<b>Female<b>','<b>Male<b>'],hole=0.3,pull=[0,0.3]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=['Active Female','Active Male'],\n",
    "        values=train.query('Is_Active==\"Yes\"').Gender.value_counts().values,\n",
    "        pull=[0,0.05,0.5],\n",
    "        hole=0.3\n",
    "        \n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=['Female Not Active','Male Not Active'],\n",
    "        values=train.query('Is_Active==\"No\"').Gender.value_counts().values,\n",
    "        pull=[0,0.2,0.5],\n",
    "        hole=0.3\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    showlegend=True,\n",
    "    title_text=\"<b>Distribution Of Gender And Active Statuses<b>\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, cols=2,subplot_titles=('','<b> Credit Product','<b>No Credit Product<b>','Residuals'),\n",
    "    vertical_spacing=0.09,\n",
    "    specs=[[{\"type\": \"pie\",\"rowspan\": 2}       ,{\"type\": \"pie\"}] ,\n",
    "           [None                               ,{\"type\": \"pie\"}]            ,                                      \n",
    "          ]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(values=train.Gender.value_counts().values,labels=['<b>Female<b>','<b>Male<b>'],hole=0.3,pull=[0,0.3]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=['Female With Credit Product','Male With Credit Product'],\n",
    "        values=train.query('Credit_Product==\"Yes\"').Gender.value_counts().values,\n",
    "        pull=[0,0.05,0.5],\n",
    "        hole=0.3\n",
    "        \n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=['Female Not With Credit Product','Male Not With Credit Product'],\n",
    "        values=train.query('Credit_Product==\"No\"').Gender.value_counts().values,\n",
    "        pull=[0,0.2,0.5],\n",
    "        hole=0.3\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    showlegend=True,\n",
    "    title_text=\"<b>Distribution Of Gender And Active Statuses<b>\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Findings__\n",
    "\n",
    "__1. Training data is positively skewed.__\n",
    "\n",
    "__2. Binary Class Imbalance.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Credit_Product'] = train['Credit_Product'].fillna(0)\n",
    "m = train['Credit_Product'].mode()\n",
    "train['Credit_Product'] = train['Credit_Product'].replace(0,m.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Credit_Product'] = test['Credit_Product'].fillna(0)\n",
    "m = test['Credit_Product'].mode()\n",
    "test['Credit_Product'] = test['Credit_Product'].replace(0,m.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the ID columns from both Train and Test set as it wont have any dependency on the target variable\n",
    "train.drop(\"ID\",axis=1,inplace=True)\n",
    "test.drop(\"ID\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a feature if according to occupation customer is active or not\n",
    "train[\"Active_occ\"]=train[\"Is_Active\"]+\"_\"+train[\"Occupation\"]\n",
    "test[\"Active_occ\"]=test[\"Is_Active\"]+\"_\"+test[\"Occupation\"]\n",
    "\n",
    "\n",
    "#creating a feature if according to gender customer is active or not\n",
    "train[\"Active_gen\"]=train[\"Gender\"]+\"_\"+train[\"Is_Active\"]\n",
    "test[\"Active_gen\"]=test[\"Gender\"]+\"_\"+test[\"Is_Active\"]\n",
    "\n",
    "\n",
    "#creating a feature if according to credit product customer is active or not\n",
    "train[\"Active_credit\"]=train[\"Credit_Product\"]+\"_\"+train[\"Is_Active\"]\n",
    "test[\"Active_credit\"]=test[\"Credit_Product\"]+\"_\"+test[\"Is_Active\"]\n",
    "\n",
    "\n",
    "#creating a feature if according to channel customer is active or not\n",
    "train[\"Active_channel\"]=train[\"Is_Active\"]+\"_\"+train[\"Channel_Code\"]\n",
    "test[\"Active_channel\"]=test[\"Is_Active\"]+\"_\"+test[\"Channel_Code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the log of Avg Account Balance\n",
    "train[\"log_Balance\"]=np.log(train[\"Avg_Account_Balance\"])\n",
    "test[\"log_Balance\"]=np.log(test[\"Avg_Account_Balance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning the age to create the age groups feature\n",
    "bins = [15,30,45,60,75,90]\n",
    "labels = ['young_adult','adult','middle-aged','old','very_old']\n",
    "train['Age_group'] = pd.cut(train['Age'],bins = bins, labels = labels)\n",
    "test['Age_group'] = pd.cut(test['Age'],bins = bins, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train['Vintage']%365)/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature to convert vintage days to weeks\n",
    "train['Vintage_weeks'] = ((train['Vintage']%365)/7).astype(int)\n",
    "test['Vintage_weeks'] = ((test['Vintage']%365)/7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#te = TargetEncoder()\n",
    "#train['Region_Code_encoding'] = te.fit_transform(train['Region_Code'].astype(str), train['Is_Lead'])\n",
    "#test['Region_Code_encoding'] = te.transform(test['Region_Code'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the categorical features\n",
    "train['Age_group'] = train['Age_group'].astype(object)\n",
    "test['Age_group'] = test['Age_group'].astype(object)\n",
    "categoricals_features=[]\n",
    "for col in train:\n",
    "  if train[col].dtypes==\"O\":\n",
    "    categoricals_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding the Categorical variables\n",
    "\n",
    "print('Transform all String features to category.\\n')\n",
    "for usecol in categoricals_features:\n",
    "    colcount = train[usecol].value_counts().index[0]\n",
    "    train[usecol] = train[usecol].fillna(colcount)\n",
    "    test[usecol]  = test[usecol].fillna(colcount)\n",
    "    \n",
    "    train[usecol] = train[usecol].astype('str')\n",
    "    test[usecol] = test[usecol].astype('str')\n",
    "    \n",
    "    #Fit LabelEncoder\n",
    "    le = LabelEncoder().fit(\n",
    "            np.unique(train[usecol].unique().tolist()+\n",
    "                      test[usecol].unique().tolist()))\n",
    "\n",
    "    #At the end 0 will be used for dropped values\n",
    "    train[usecol] = le.transform(train[usecol])+1\n",
    "    test[usecol]  = le.transform(test[usecol])+1\n",
    "    \n",
    "    train[usecol] = train[usecol].replace(np.nan, -1).astype('int')\n",
    "    test[usecol]  = test[usecol].replace(np.nan , -1).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the target variable\n",
    "X= train.loc[:, train.columns != \"Is_Lead\"]\n",
    "y = train.loc[:, train.columns == \"Is_Lead\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsampling using the SMOTE\n",
    "#print(\"Before UpSampling, counts of label '1': {}\".format(sum(y.Is_Lead==1)))\n",
    "#print(\"Before UpSampling, counts of label '0': {} \\n\".format(sum(y.Is_Lead==0)))\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 1 ,k_neighbors = 5, random_state=1)   \n",
    "X_smote, y = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling using standard scaler\n",
    "#sc = StandardScaler()\n",
    "#X_smote = sc.fit_transform(X_smote)\n",
    "#test = sc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "X_smote = sc.fit_transform(X_smote)\n",
    "test = sc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote = pd.DataFrame(X_smote,columns=X.columns)\n",
    "test=pd.DataFrame(test,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y,columns=['Is_Lead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(X_smote, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    # params specifies the XGBoost hyperparameters to be tuned\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 150, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, .1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),  \n",
    "        'objective': 'binary:logistic'\n",
    "    }\n",
    "    \n",
    "    bst = xgb.train(params, dtrain)\n",
    "    preds = bst.predict(dvalid)\n",
    "\n",
    "    pred_labels = np.rint(preds)\n",
    "    # trials will be evaluated based on their accuracy on the test set\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_valid, pred_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hyperparameter tuning using optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective,n_trials=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'binary:logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training the model in 5 fold and 2 repeats\n",
    "N_FOLDS = 5\n",
    "N_REPEAT = 2\n",
    "\n",
    "def training(n_repeat = 1, n_folds = 5):\n",
    "    models = []\n",
    "    F1_scores = []\n",
    "    kfold = StratifiedKFold(n_folds, shuffle = True)\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(X_smote,y), 1):\n",
    "        print('-'*85)\n",
    "        print(f'Repeat {n_repeat}, Fold {fold}')\n",
    "        \n",
    "        X_train = X_smote.values[train_index]\n",
    "        y_train = y.values[train_index].ravel()\n",
    "        X_test = X_smote.values[test_index]\n",
    "        y_test = y.values[test_index].ravel()\n",
    "        \n",
    "        model = xgb.XGBClassifier(**best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        f1 = roc_auc_score(y_test,model.predict_proba(X_test)[:,1])\n",
    "        print(f'AUC: {f1}')\n",
    "        print(classification_report(y_test, y_pred, labels=[0,1]))\n",
    "        \n",
    "        models.append(model)\n",
    "        F1_scores.append(f1)\n",
    "    return models, np.mean(F1_scores)\n",
    "\n",
    "models = []\n",
    "mean_f1s = []\n",
    "\n",
    "for i in range(1, N_REPEAT+1):\n",
    "    m, f = training(i, N_FOLDS)\n",
    "    print('-'*85)\n",
    "    models = models + m\n",
    "    mean_f1s.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction of 10 models and taking the mean\n",
    "pred = np.array([])\n",
    "pred1=models[0].predict_proba(test.values)[:,1]\n",
    "pred2=models[1].predict_proba(test.values)[:,1]\n",
    "pred3=models[2].predict_proba(test.values)[:,1]\n",
    "pred4=models[3].predict_proba(test.values)[:,1]\n",
    "pred5=models[4].predict_proba(test.values)[:,1]\n",
    "pred6=models[5].predict_proba(test.values)[:,1]\n",
    "pred7=models[6].predict_proba(test.values)[:,1]\n",
    "pred8=models[7].predict_proba(test.values)[:,1]\n",
    "pred9=models[8].predict_proba(test.values)[:,1]\n",
    "pred10=models[9].predict_proba(test.values)[:,1]\n",
    "\n",
    "\n",
    "for i in range(0,len(test.values)):\n",
    "    pred = np.append(pred, np.mean([pred1[i], pred2[i], pred3[i], pred4[i], pred5[i],\n",
    "                                   pred6[i], pred7[i], pred8[i], pred9[i], pred10[i]\n",
    "                                  ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the submission file\n",
    "test_new = pd.read_csv('/home/divyanka/Downloads/test_mSzZ8RL.csv')\n",
    "submission_df = pd.DataFrame({'ID': test_new['ID'].values,'Is_Lead': pred})\n",
    "submission_df.Is_Lead.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('/home/divyanka/Downloads/Final_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Attempt and Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Is_Lead',axis=1)\n",
    "y = train['Is_Lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cross_val(X, y, model, params, folds=3):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=21)\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold: {fold}\")\n",
    "        x_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        x_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "        alg = model(**params)\n",
    "        alg.fit(x_train, y_train,\n",
    "                eval_set=[(x_test, y_test)],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=400)\n",
    "\n",
    "        pred = alg.predict_proba(x_test)[:, 1]\n",
    "        roc_score = roc_auc_score(y_test, pred)\n",
    "        print(f\"roc_auc_score: {roc_score}\")\n",
    "        print(\"-\"*50)\n",
    "    \n",
    "    return alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params= {'learning_rate': 0.094, \n",
    "             'n_estimators': 20000, \n",
    "             'max_bin': 94,\n",
    "             'num_leaves': 12, \n",
    "             'max_depth': 27, \n",
    "             'reg_alpha': 8.457, \n",
    "             'reg_lambda': 6.853, \n",
    "             'subsample': 0.749}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgb_model = cross_val(X_smote, y, LGBMClassifier, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params= {'n_estimators': 20000, \n",
    "             'max_depth': 6, \n",
    "             'learning_rate': 0.0201, \n",
    "             'reg_lambda': 29.326, \n",
    "             'subsample': 0.818, \n",
    "             'colsample_bytree': 0.235, \n",
    "             'colsample_bynode': 0.820, \n",
    "             'colsample_bylevel': 0.453}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = cross_val(X_smote, y, XGBClassifier, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_lgb = lgb_model.predict_proba(test)[:,1]\n",
    "pred_test_xgb = xgb_model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the submission file\n",
    "test_new = pd.read_csv('/home/divyanka/Downloads/test_mSzZ8RL.csv')\n",
    "submission_df = pd.DataFrame({'ID': test_new['ID'].values,'Is_Lead': pred_test_lgb})\n",
    "submission_df.to_csv('/home/divyanka/Downloads/Final_submission_lgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the submission file\n",
    "test_new = pd.read_csv('/home/divyanka/Downloads/test_mSzZ8RL.csv')\n",
    "submission_df = pd.DataFrame({'ID': test_new['ID'].values,'Is_Lead': pred_test_xgb})\n",
    "submission_df.to_csv('/home/divyanka/Downloads/Final_submission_xgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params= {'n_estimators': 20000, \n",
    "                  'depth': 4, \n",
    "                  'learning_rate': 0.023, \n",
    "                  'colsample_bylevel': 0.655, \n",
    "                  'bagging_temperature': 0.921, \n",
    "                  'l2_leaf_reg': 10.133}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = cross_val(X_smote, y, CatBoostClassifier, cat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_cat = cat_model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the submission file\n",
    "test_new = pd.read_csv('/home/divyanka/Downloads/test_mSzZ8RL.csv')\n",
    "submission_df = pd.DataFrame({'ID': test_new['ID'].values,'Is_Lead': pred_test_cat})\n",
    "submission_df.to_csv('/home/divyanka/Downloads/Final_submission_cat.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = (pred_test_lgb + pred_test_cat+pred_test_xgb)/3\n",
    "#creating the submission file\n",
    "#test_new = pd.read_csv('/home/divyanka/Downloads/test_mSzZ8RL.csv')\n",
    "#submission_df = pd.DataFrame({'ID': test_new['ID'].values,'Is_Lead': prediction})\n",
    "#submission_df.to_csv('/home/divyanka/Downloads/Final_submission_lgbm.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
